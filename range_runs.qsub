#!/bin/bash -l

# Run this file using 'qsub range_runs.qsub'
#
# All lines starting with "#" are comments
# All lines starting with "#$" are SGE qsub commands
# 

#  Specify a project to use (Required for BUMC projects).
#$ -P hep-ce

#  Give this job a name
#$ -N respond

#  Join standard output and error to a single file
#$ -j y

#  Name the file where to redirect standard output and error
#$ -o respond.qlog

#  Request time needed for job to run (default: 12 hours)
#$ -l h_rt=12:00:00

#  Send an email when the job begins and when it ends running
#  (b = when job begins, a = if job aborts, e = when job ends)
#$ -m a

# Whom to send the email to
#$ -M golnaz89@bu.edu

# use tasks, comment this line if running on single node.
#$ -t 1-2

# Now let's keep track of some information just in case anything goes wrong
echo "=========================================================="
echo "Starting on : $(date)"
echo "Task index number : $SGE_TASK_ID"
echo "=========================================================="

# Load any modules you might want to use.
module load R/3.5.1
module load gcc/8.1.0

# Run the commands you need to run for your job

# There should not be any output folder inside respond folder or each time all of these large folders will be coppied to compute nodes. Also the mkdir command will not work.
respond=/project/hep-ce/golnaz/workspace/respond_golnaz

# The following folder should only include initially empty output folders, one for each strategy
respondnb=/projectnb/hep-ce/golnaz/workspace/respond

# copy the project to a temporary folder on each compute node. This folder would be 
# updated by the R code to manipulate the inputs. The original inputs inside /project directory will not change.

mkdir  $TMPDIR/$SGE_TASK_ID
cp -R   $respond/. $TMPDIR/$SGE_TASK_ID
cd   $TMPDIR/$SGE_TASK_ID

mkdir org_files
cp -r input* org_files
cp -r shared_data org_files

# create the empty testing folders for outputs (1 folder for each strategy)
# enter number of strategies as the upper bound of the for loop
for i in {1..2}
do
mkdir output$i
done

# assign run index
# idx is used as the row_id of input table(symbol table), the seed(if needed) and index of output files. It depends on number of runs per SGE_TASK_ID. Make sure to update its range appropriately.
start_idx=$((($SGE_TASK_ID-1)*12+1))
stop_idx=$(($start_idx+11))

for idx in $(seq $start_idx 1 $stop_idx)
do
# copy initial inputs so the new run doesn't use the updated inputs of the last run.
cp -r org_files/* ./

# update input files based on index
Rscript codes/generate_inputs/update_files.R $idx

Rscript codes/respond_main.R 1 $idx
Rscript codes/respond_main.R 2 $idx

# copy the desired outputs (here, general_stats.csv) to respondnb folder. You can add more inputs/outputs here.
for dir in output*
do
cp $dir/general_stats$idx.csv $respondnb/$dir
done

# If the error files are not empty, copy it to main directory
file_size=$(stat --format=%s errors$idx.txt)
if [ $file_size -ne 0 ]
then
cp errors$idx.txt $respond
fi
file_size2=$(stat --format=%s update_files_errors$idx.txt)
if [ $file_size2 -ne 0 ]
then
cp update_files_errors$idx.txt $respond
fi

# copy input folders, for test only
cp -r input* $respondnb/inputs$idx
cp -r shared_data $respondnb/inputs$idx

done

echo "=========================================================="
echo "Finished on : $(date)"
echo "=========================================================="
